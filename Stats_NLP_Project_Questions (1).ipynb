{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stats_NLP_Project_Questions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rc_ahEnTF9m",
        "colab_type": "text"
      },
      "source": [
        "# Predict tags on StackOverflow with linear models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5hmogPBTF9p",
        "colab_type": "text"
      },
      "source": [
        "In this assignment you will learn how to predict tags for posts from [StackOverflow](https://stackoverflow.com). To solve this task you will use multilabel classification approach.\n",
        "\n",
        "### Libraries\n",
        "\n",
        "In this task you will need the following libraries:\n",
        "- [Numpy](http://www.numpy.org) — a package for scientific computing.\n",
        "- [Pandas](https://pandas.pydata.org) — a library providing high-performance, easy-to-use data structures and data analysis tools for the Python\n",
        "- [scikit-learn](http://scikit-learn.org/stable/index.html) — a tool for data mining and data analysis.\n",
        "- [NLTK](http://www.nltk.org) — a platform to work with natural language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSq4Uzh6TF9q",
        "colab_type": "text"
      },
      "source": [
        "### Data\n",
        "\n",
        "You can find all data required for this assignment into the folder `/data`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V1gba1KTF9r",
        "colab_type": "text"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnvsWcP9TF9t",
        "colab_type": "text"
      },
      "source": [
        "For this assignment you will need to use a list of stop words. It can be downloaded from *nltk*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-RxVRvsTF9u",
        "colab_type": "code",
        "outputId": "e166bf98-9932-4cbd-8c2c-80a108f6c9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErHWjimITF91",
        "colab_type": "text"
      },
      "source": [
        "In this task you will deal with a dataset of post titles from StackOverflow. You are provided a split to 3 sets: *train*, *validation* and *test*. All corpora (except for *test*) contain titles of the posts and corresponding tags (100 tags are available). The *test* set doesn't contain answers. Upload the corpora using *pandas* and look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ufeO-nfVGha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ast import literal_eval\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1f7azAI0ztj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ced92e01-ba42-4c16-e44f-21504dbf36a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDahiblaU-e7",
        "colab_type": "text"
      },
      "source": [
        "Literal_eval package takes care of the preprocessing for the string so that it can be used in python. To know more on literal_eval please see the below documentation <br>\n",
        "https://kite.com/python/docs/ast.literal_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bubX7TSLVLXR",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: Create training, testing and validation data from the files given. Use title to be the independent variable and tags to be the dependent variable ( 5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBFMf3bhVPb_",
        "colab_type": "text"
      },
      "source": [
        "Note: Ensure you apply literal_eval function on the tags column to ensure all the tags are readable in python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8iH7o77TF96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pd.read_csv('/content/drive/My Drive/DL Project/Statistical NLP/Files_required_for_Stats_NLP_Project/train.tsv',delimiter='\\t',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPaUfSVvTF99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d961bdf8-4dd6-4ddb-e00b-836a97a9c852"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How to draw a stacked dotplot in R?</td>\n",
              "      <td>['r']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mysql select all records where a datetime fiel...</td>\n",
              "      <td>['php', 'mysql']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How to terminate windows phone 8.1 app</td>\n",
              "      <td>['c#']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get current time in a specific country via jquery</td>\n",
              "      <td>['javascript', 'jquery']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Configuring Tomcat to Use SSL</td>\n",
              "      <td>['java']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title                      tags\n",
              "0                How to draw a stacked dotplot in R?                     ['r']\n",
              "1  mysql select all records where a datetime fiel...          ['php', 'mysql']\n",
              "2             How to terminate windows phone 8.1 app                    ['c#']\n",
              "3  get current time in a specific country via jquery  ['javascript', 'jquery']\n",
              "4                      Configuring Tomcat to Use SSL                  ['java']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb5CYdYq10kV",
        "colab_type": "text"
      },
      "source": [
        "The train set has the title and the tags in which its clasified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpnlpSkI2qKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train['tags'] = X_train['tags'].apply(literal_eval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJJa1BY-20jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "6adc1cae-331b-4e4d-b5ca-3aeb8971e924"
      },
      "source": [
        "X_train.head(10)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How to draw a stacked dotplot in R?</td>\n",
              "      <td>[r]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mysql select all records where a datetime fiel...</td>\n",
              "      <td>[php, mysql]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How to terminate windows phone 8.1 app</td>\n",
              "      <td>[c#]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>get current time in a specific country via jquery</td>\n",
              "      <td>[javascript, jquery]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Configuring Tomcat to Use SSL</td>\n",
              "      <td>[java]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Awesome nested set plugin - how to add new chi...</td>\n",
              "      <td>[ruby-on-rails]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How to create map from JSON response in Ruby o...</td>\n",
              "      <td>[ruby, ruby-on-rails-3, json]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>rspec test if method is called</td>\n",
              "      <td>[ruby]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SpringBoot Catalina LifeCycle Exception</td>\n",
              "      <td>[java, spring, spring-mvc]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How to import data from excel to mysql databas...</td>\n",
              "      <td>[php, codeigniter]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title                           tags\n",
              "0                How to draw a stacked dotplot in R?                            [r]\n",
              "1  mysql select all records where a datetime fiel...                   [php, mysql]\n",
              "2             How to terminate windows phone 8.1 app                           [c#]\n",
              "3  get current time in a specific country via jquery           [javascript, jquery]\n",
              "4                      Configuring Tomcat to Use SSL                         [java]\n",
              "5  Awesome nested set plugin - how to add new chi...                [ruby-on-rails]\n",
              "6  How to create map from JSON response in Ruby o...  [ruby, ruby-on-rails-3, json]\n",
              "7                     rspec test if method is called                         [ruby]\n",
              "8            SpringBoot Catalina LifeCycle Exception     [java, spring, spring-mvc]\n",
              "9  How to import data from excel to mysql databas...             [php, codeigniter]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNGyYQ933JJd",
        "colab_type": "text"
      },
      "source": [
        "Applied literal evaluation to preprocess the tags string and making it ready for it to be used in python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4pPOmFvTF-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = pd.read_csv('/content/drive/My Drive/DL Project/Statistical NLP/Files_required_for_Stats_NLP_Project/test.tsv',delimiter='\\t',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFMcmWS31v5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e39e6e3e-37a1-4a79-8d27-6a990996719d"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Warning: mysql_query() expects parameter 2 to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>get click coordinates from &lt;input type='image'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How to implement cloud storage for media asset...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is catcomplete in jQuery's autocomplete p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Error building Android app with Cordova 3.1 CLI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title\n",
              "0  Warning: mysql_query() expects parameter 2 to ...\n",
              "1  get click coordinates from <input type='image'...\n",
              "2  How to implement cloud storage for media asset...\n",
              "3  What is catcomplete in jQuery's autocomplete p...\n",
              "4    Error building Android app with Cordova 3.1 CLI"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCjJgL2P16u5",
        "colab_type": "text"
      },
      "source": [
        "The test set has only titles for which we need to predict the tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USlubitlTF-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = pd.read_csv('/content/drive/My Drive/DL Project/Statistical NLP/Files_required_for_Stats_NLP_Project/validation.tsv',delimiter='\\t',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM0zbUOy1_8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val['tags'] = X_val['tags'].apply(literal_eval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwtxzPEu3ZpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "86bc9fe3-5d1f-4bef-e9db-6092ec202a8f"
      },
      "source": [
        "X_val.head()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why odbc_exec always fail?</td>\n",
              "      <td>[php, sql]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Access a base classes variable from within a c...</td>\n",
              "      <td>[javascript]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Content-Type \"application/json\" not required i...</td>\n",
              "      <td>[ruby-on-rails, ruby]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sessions in Sinatra: Used to Pass Variable</td>\n",
              "      <td>[ruby, session]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Getting error - type \"json\" does not exist - i...</td>\n",
              "      <td>[ruby-on-rails, ruby, json]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title                         tags\n",
              "0                         Why odbc_exec always fail?                   [php, sql]\n",
              "1  Access a base classes variable from within a c...                 [javascript]\n",
              "2  Content-Type \"application/json\" not required i...        [ruby-on-rails, ruby]\n",
              "3         Sessions in Sinatra: Used to Pass Variable              [ruby, session]\n",
              "4  Getting error - type \"json\" does not exist - i...  [ruby-on-rails, ruby, json]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30U5QGhW2DBp",
        "colab_type": "text"
      },
      "source": [
        "Validation set is on which I will test the model to predict the accuracy and treat it more as the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDe1m40F38si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = X_train['title'].values, X_train['tags'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJloyhDO4Br6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val, y_val = X_val['title'].values, X_val['tags'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltJAsSjQiJx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = X_test['title'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcb3kXUSTF-M",
        "colab_type": "text"
      },
      "source": [
        "## Task 2 (Pre-processing). Implement the function *text_prepare* following the instructions. After that, run the function *test_test_prepare* to test it on tiny cases. (10 points)\n",
        "\n",
        "One of the most known difficulties when working with natural data is that it's unstructured. For example, if you use it \"as is\" and extract tokens just by splitting the titles by whitespaces, you will see that there are many \"weird\" tokens like *3.5*, *?*,  *{}*, etc. To prevent the problems, it's usually useful to prepare the data in a custom way\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBSchmxtTF-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "43c33142-eb6e-4bc2-cb84-c34d849dfc47"
      },
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI1plv6WTF-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def text_prepare(text): ### The function will take in text and lower case it remove the stopwords, symbols and return it.\n",
        "    text = text.lower() ### code which can change the input text to lowercase.\n",
        "    text = re.sub(REPLACE_BY_SPACE_RE,' ',text) ### code which replaces REPLACE_BY_SPACE_RE (above mentioned) symbols by space in text\n",
        "    text = re.sub(BAD_SYMBOLS_RE,'',text) ### code which deletes symbols which are in BAD_SYMBOLS_RE (above mentioned) from text\n",
        "    ### Write a code which deletes stopwords from text\n",
        "    tk_word=word_tokenize(text)\n",
        "    sen = [w for w in tk_word if not w in STOPWORDS] \n",
        "    lenght_of_string=len(sen)\n",
        "    text_new=\"\"\n",
        "    for w in sen:\n",
        "        if w!=sen[lenght_of_string-1]:\n",
        "             text_new=text_new+w+\" \" # when w is not the last word so separate by whitespace\n",
        "        else:\n",
        "            text_new=text_new+w\n",
        "            \n",
        "    text = text_new\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5LQEgMATF-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_text_prepare():\n",
        "    examples = [\"SQL Server - any equivalent of Excel's CHOOSE function?\",\n",
        "                \"How to free c++ memory vector<int> * arr?\"]\n",
        "    answers = [\"sql server equivalent excels choose function\", \n",
        "               \"free c++ memory vectorint arr\"]\n",
        "    for ex, ans in zip(examples, answers):\n",
        "        if text_prepare(ex) != ans:\n",
        "            return \"Wrong answer for the case: '%s'\" % ex\n",
        "    return 'Basic tests are passed.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t2DpralVokG",
        "colab_type": "text"
      },
      "source": [
        "Execute the test_text_prepare function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihi8I2yQTF-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "871072ce-ae2b-48ce-f570-172c237cdd5a"
      },
      "source": [
        "print(test_text_prepare())"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Basic tests are passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ettHAZ8eVt1R",
        "colab_type": "text"
      },
      "source": [
        "*Note: You should pass the above test to ensure the text preprocessing is done before our analysis*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV5JC6HXTF-k",
        "colab_type": "text"
      },
      "source": [
        "Now we can preprocess the titles using function *text_prepare* and  making sure that the headers don't have bad symbols:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOZKuHnGTF-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = [text_prepare(text) for text in x_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfWls32MV5Uu",
        "colab_type": "text"
      },
      "source": [
        "Print the top 5 elements in x_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BP3LiGsTF-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "121ef979-a74b-47cf-daeb-046169ba21d8"
      },
      "source": [
        "x_train[0:5]"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['draw stacked dotplot r',\n",
              " 'mysql select records datetime field less specified value',\n",
              " 'terminate windows phone 81 app',\n",
              " 'get current time specific country via jquery',\n",
              " 'configuring tomcat use ssl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku1tFKWs9YMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = [text_prepare(text) for text in x_val]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUvqWNhJ9lP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e928a38c-2ee1-46c6-807d-e0b0d33584c4"
      },
      "source": [
        "x_val[5]"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'library found'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k82OA7rbifR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = [text_prepare(text) for text in x_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At_ZTeqTTF-t",
        "colab_type": "text"
      },
      "source": [
        "## Task 2 (WordsTagsCount) - Find 3 most popular tags and 3 most popular words in the train data. - 5 points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2mT1f7gWKSu",
        "colab_type": "text"
      },
      "source": [
        "Note: The words which appear the most are considered as popular in this case!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-eQoxipTF-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9715b895-7863-403e-d128-c214410eefc5"
      },
      "source": [
        "print(len(x_train))\n",
        "\n",
        "tags_counts = {}\n",
        "words_counts = {}\n",
        "def c_counter(corpus_list):\n",
        "    a_dict= {}\n",
        "    for corp in corpus_list:\n",
        "        if type(corp) == type('keyword'):\n",
        "            for word in corp.split():\n",
        "                if word not in a_dict.keys():\n",
        "                    a_dict[word] = 1\n",
        "                else:   \n",
        "                     a_dict[word] = a_dict[word] + 1\n",
        "        else:\n",
        "            for word in corp:\n",
        "                if word not in a_dict.keys():\n",
        "                    a_dict[word] = 1\n",
        "                else:   \n",
        "                     a_dict[word] = a_dict[word] + 1\n",
        "            \n",
        "    return a_dict\n",
        "                \n",
        "words_counts = c_counter(x_train)\n",
        "\n",
        "tags_counts = c_counter(list(y_train))\n",
        "\n",
        "items = [(v, k) for k, v in tags_counts.items()]\n",
        "items.sort()\n",
        "items.reverse()\n",
        "items[:5]"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(19078, 'javascript'),\n",
              " (19077, 'c#'),\n",
              " (18661, 'java'),\n",
              " (13907, 'php'),\n",
              " (8940, 'python')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI2NS3hnkNDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "de6fe59a-101d-4188-b3d4-9b2b6d2a8c0e"
      },
      "source": [
        "# Dictionary of all tags from train corpus with their counts.\n",
        "tags_counts = tag_counts\n",
        "# Dictionary of all words from train corpus with their counts.\n",
        "words_counts = Counter(words)\n",
        "print(tags_counts)\n",
        "print(tags_counts.keys())\n",
        "most_common_tags = sorted(tags_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "\n",
        "print(most_common_words)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'javascript': 19078, 'c#': 19077, 'java': 18661, 'php': 13907, 'python': 8940, 'jquery': 7510, 'c++': 6469, 'html': 4668, 'objective-c': 4338, 'asp.net': 3939, '.net': 3872, 'ruby-on-rails': 3344, 'ios': 3256, 'c': 3119, 'mysql': 3092, 'android': 2818, 'ruby': 2326, 'arrays': 2277, 'json': 2026, 'vb.net': 1918, 'iphone': 1909, 'django': 1835, 'css': 1769, 'ajax': 1767, 'r': 1727, 'string': 1573, 'winforms': 1468, 'swift': 1465, 'regex': 1442, 'angularjs': 1353, 'xml': 1347, 'spring': 1346, 'wpf': 1289, 'sql': 1272, 'asp.net-mvc': 1244, 'multithreading': 1118, 'eclipse': 992, 'linq': 964, 'xcode': 900, 'forms': 872, 'html5': 842, 'windows': 838, 'hibernate': 807, 'linux': 793, 'codeigniter': 786, 'node.js': 771, 'swing': 759, 'database': 740, 'list': 693, 'ruby-on-rails-3': 692, 'jsp': 680, 'image': 672, 'entity-framework': 649, 'web-services': 633, 'spring-mvc': 618, 'visual-studio-2010': 588, 'sql-server': 585, 'file': 582, 'sockets': 579, 'visual-studio': 574, 'date': 560, 'validation': 558, 'datetime': 557, 'laravel': 525, 'performance': 512, 'class': 509, 'facebook': 508, 'cocoa-touch': 507, 'numpy': 502, 'twitter-bootstrap': 501, 'servlets': 498, 'osx': 490, 'function': 487, 'pandas': 479, 'wordpress': 478, 'uitableview': 460, 'rest': 456, 'qt': 451, 'unit-testing': 449, 'excel': 443, 'apache': 441, 'xaml': 438, 'csv': 435, 'maven': 432, 'selenium': 431, 'oop': 425, 'python-2.7': 421, 'generics': 420, 'algorithm': 419, 'session': 415, 'google-maps': 408, 'parsing': 403, 'opencv': 401, 'dom': 400, 'wcf': 389, 'loops': 389, 'python-3.x': 379, 'sorting': 375, 'mongodb': 350, 'pointers': 350})\n",
            "dict_keys(['r', 'php', 'mysql', 'c#', 'javascript', 'jquery', 'java', 'ruby-on-rails', 'ruby', 'ruby-on-rails-3', 'json', 'spring', 'spring-mvc', 'codeigniter', 'class', 'html', 'ios', 'c++', 'eclipse', 'python', 'list', 'objective-c', 'swift', 'xaml', 'asp.net', 'wpf', 'multithreading', 'image', 'performance', 'twitter-bootstrap', 'linq', 'xml', 'numpy', 'ajax', 'django', 'laravel', 'android', 'rest', 'asp.net-mvc', 'web-services', 'string', 'excel', 'winforms', 'arrays', 'c', 'sockets', 'osx', 'entity-framework', 'mongodb', 'opencv', 'xcode', 'uitableview', 'algorithm', 'python-2.7', 'angularjs', 'dom', 'swing', '.net', 'vb.net', 'google-maps', 'hibernate', 'wordpress', 'iphone', 'sql', 'visual-studio', 'linux', 'facebook', 'database', 'file', 'generics', 'visual-studio-2010', 'regex', 'html5', 'jsp', 'csv', 'forms', 'validation', 'parsing', 'function', 'pandas', 'sorting', 'qt', 'wcf', 'css', 'date', 'node.js', 'sql-server', 'unit-testing', 'python-3.x', 'loops', 'windows', 'pointers', 'oop', 'datetime', 'servlets', 'session', 'cocoa-touch', 'apache', 'selenium', 'maven'])\n",
            "[('using', 8241), ('c', 8145), ('php', 5587)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkwg8_WNTF-3",
        "colab_type": "text"
      },
      "source": [
        "We are assuming that *tags_counts* and *words_counts* are dictionaries like `{'some_word_or_tag': frequency}`. After applying the sorting procedure, results will be look like this: `[('most_popular_word_or_tag', frequency), ('less_popular_word_or_tag', frequency), ...]`.\n",
        "\n",
        "eg: \n",
        "Tag 1 - 100 Tag 2 - 65 Tag 3 - 250 <br>\n",
        "after sorting looks like, <br>\n",
        "Tag 3 - 250 Tag 1 - 100 Tag 2 - 65"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk7M4uJ_TF-8",
        "colab_type": "text"
      },
      "source": [
        "## Task - 3 Transforming text to a vector (10 points)\n",
        "\n",
        "Machine Learning algorithms work with numeric data and we cannot use the provided text data \"as is\". There are many ways to transform text data to numeric vectors. In this task you will try to use two of them.\n",
        "\n",
        "#### Bag of words\n",
        "\n",
        "One of the well-known approaches is a *bag-of-words* representation. To create this transformation, follow the steps:\n",
        "1. Find *N* most popular words in train corpus and numerate them. Now we have a dictionary of the most popular words.\n",
        "2. For each title in the corpora create a zero vector with the dimension equals to *N*.\n",
        "3. For each text in the corpora iterate over words which are in the dictionary and increase by 1 the corresponding coordinate.\n",
        "\n",
        "Let's try to do it for a toy example. Imagine that we have *N* = 4 and the list of the most popular words is \n",
        "\n",
        "    ['hi', 'you', 'me', 'are']\n",
        "\n",
        "Then we need to numerate them, for example, like this: \n",
        "\n",
        "    {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
        "\n",
        "And we have the text, which we want to transform to the vector:\n",
        "\n",
        "    'hi how are you'\n",
        "\n",
        "For this text we create a corresponding zero vector \n",
        "\n",
        "    [0, 0, 0, 0]\n",
        "    \n",
        "And iterate over all words, and if the word is in the dictionary, we increase the value of the corresponding position in the vector:\n",
        "\n",
        "    'hi':  [1, 0, 0, 0]\n",
        "    'how': [1, 0, 0, 0] # word 'how' is not in our dictionary\n",
        "    'are': [1, 0, 0, 1]\n",
        "    'you': [1, 1, 0, 1]\n",
        "\n",
        "The resulting vector will be \n",
        "\n",
        "    [1, 1, 0, 1]\n",
        "   \n",
        "Implement the described encoding in the function *my_bag_of_words* with the size of the dictionary equals to 5000. To find the most common words use train data. You can test your code using the function *test_my_bag_of_words*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ER1oq48TF-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DICT_SIZE = 5000\n",
        "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:5000] \n",
        "WORDS_TO_INDEX = {}\n",
        "INDEX_TO_WORDS = {}\n",
        "for i in range(0,5000):\n",
        "    WORDS_TO_INDEX[most_common_words[i][0]]=i\n",
        "    INDEX_TO_WORDS[i]=most_common_words[i][0]\n",
        "ALL_WORDS = WORDS_TO_INDEX.keys()\n",
        "\n",
        "def my_bag_of_words(text, words_to_index, dict_size):\n",
        "    result_vector = np.zeros(dict_size)\n",
        "    y=text.split(\" \")\n",
        "    for i in range(0,len(y)):\n",
        "        for key,value in words_to_index.items():\n",
        "            if y[i]==key:\n",
        "                result_vector[words_to_index[key]]=result_vector[words_to_index[key]]+1\n",
        "    return result_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnLYWnsaTF_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_my_bag_of_words():\n",
        "    words_to_index = {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
        "    examples = ['hi how are you']\n",
        "    answers = [[1, 1, 0, 1]]\n",
        "    for ex, ans in zip(examples, answers):\n",
        "        if (my_bag_of_words(ex, words_to_index, 4) != ans).any():\n",
        "            return \"Wrong answer for the case: '%s'\" % ex\n",
        "    return 'Basic tests are passed.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOlSiUqEW3jD",
        "colab_type": "text"
      },
      "source": [
        "Execute the test_text_prepare function <br>\n",
        "*<u>Note:</u> You should pass the above test to ensure BOW is working correctly!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqWhoF24TF_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fcc10e9-a7ab-4cef-ba93-042ee07a225c"
      },
      "source": [
        "print(test_my_bag_of_words())"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Basic tests are passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXW3ALCITF_H",
        "colab_type": "text"
      },
      "source": [
        "Now apply the implemented function to all samples (this might take up to a minute):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m39xHB2yTF_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import sparse as sp_sparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DZwPWB1TF_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b295e277-d3c0-4179-d441-38e971e458f7"
      },
      "source": [
        "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in x_train])\n",
        "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in x_val])\n",
        "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in x_test])\n",
        "print('x_train shape ', X_train_mybag.shape)\n",
        "print('x_val shape ', X_val_mybag.shape)\n",
        "print('X_test shape ', X_test_mybag.shape)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape  (100000, 5000)\n",
            "x_val shape  (30000, 5000)\n",
            "X_test shape  (20000, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPXTUeNSTF_N",
        "colab_type": "text"
      },
      "source": [
        "As you might notice, we transform the data to sparse representation, to store the useful information efficiently. There are many types: of such representations, however sklearn algorithms can work only with  csr matrix, so we will use this one.<br>\n",
        "<u>Documentations on sparse matrix:</u> <br>\n",
        "(https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) \n",
        "(https://docs.scipy.org/doc/scipy/reference/sparse.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8AMzsVxTF_Q",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "For the 11th row in *X_train_mybag* find how many non-zero elements it has. In this task the answer (variable *non_zero_elements_count*) should be a number, e.g. 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOetzSLzTF_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99c4e9b9-e63c-4304-b32e-cf8c2089c592"
      },
      "source": [
        "row = X_train_mybag[11].toarray()[0]\n",
        "non_zero_elements_count=0\n",
        "for i in range(0,5000):\n",
        "    if (row[i]==1):\n",
        "        non_zero_elements_count=non_zero_elements_count+1\n",
        "\n",
        "print(non_zero_elements_count)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjS2YeovT_36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45fc86fe-1cb8-4571-c0d9-cd4418046f2c"
      },
      "source": [
        "row = X_val_mybag[20].toarray()[0]\n",
        "non_zero_elements_count=0\n",
        "for i in range(0,5000):\n",
        "    if (row[i]==1):\n",
        "        non_zero_elements_count=non_zero_elements_count+1\n",
        "\n",
        "print(non_zero_elements_count)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPKTiEX1XTUi",
        "colab_type": "text"
      },
      "source": [
        "Testing on validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYAFKGfKTF_V",
        "colab_type": "text"
      },
      "source": [
        "## Task 4 - TF-IDF (5 points)\n",
        "\n",
        "The second approach extends the bag-of-words framework by taking into account total frequencies of words in the corpora. It helps to penalize too frequent words and provide better features space. \n",
        "\n",
        "Implement function *tfidf_features* using class  from *scikit-learn*. Use *train* corpus to train a vectorizer. Don't forget to take a look into the arguments that you can pass to it. We suggest that you filter out too rare words (occur less than in 5 titles) and too frequent words (occur more than in 90% of the titles). Also, use bigrams along with unigrams in your vocabulary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s3uEKmjYpuh",
        "colab_type": "text"
      },
      "source": [
        "## Write a function which takes x_train, x_val and x_test as input and return the tf-idf features of the same and the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkz1RYsBTF_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV-UQFMDXlbk",
        "colab_type": "text"
      },
      "source": [
        "I am modifying the below code as I am not working with the test set as tags for test set is not available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6V7FPirTF_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf_features(x_train, x_val,x_test):\n",
        "  tfidf_vectorizer =  TfidfVectorizer(min_df=5,max_df=0.9,ngram_range=(1,2),token_pattern= '(\\S+)')#  '(\\S+)'\n",
        "  x_train_tfidf=tfidf_vectorizer.fit_transform(x_train)\n",
        "  x_val_tfidf=tfidf_vectorizer.transform(x_val)\n",
        "  x_test_tfidf=tfidf_vectorizer.transform(x_test)\n",
        "  return x_train_tfidf, x_val_tfidf, x_test_tfidf, tfidf_vectorizer.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySnV2zCBTF_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_tfidf, x_val_tfidf, x_test_tfidf, tfidf_vocab = tfidf_features(x_train, x_val, x_test)\n",
        "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_aopTTNL5G1",
        "colab_type": "text"
      },
      "source": [
        "Print the index of string \"C#\" in the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ-3wqTTMCRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "633caf7d-18bb-48f2-c75c-52f09c0ba2ef"
      },
      "source": [
        "print('Index of string c # in vocabulary is: '+str(tfidf_vocab['c #']))"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index of string c # in vocabulary is: 1920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYYO2kdiTF_6",
        "colab_type": "text"
      },
      "source": [
        "## Task 5: Classification (15 points)\n",
        "MultiLabel classifier\n",
        "\n",
        "As we have noticed before, in this task each example can have multiple tags. To deal with such kind of prediction, we need to transform labels in a binary form and the prediction will be a mask of 0s and 1s. For this purpose it is convenient to use MultiLabelBinarizer from sklearn. <br>\n",
        "<u>Documentation:</u> <br>\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojeCe_e_TF_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8JYQr8YTF_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
        "y_train = mlb.fit_transform(y_train)\n",
        "y_val = mlb.fit_transform(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN1NUA3DTGAB",
        "colab_type": "text"
      },
      "source": [
        "In this task we suggest to use One-vs-Rest approach, which is implemented in [OneVsRestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) class. In this approach *k* classifiers (= number of tags) are trained. As a basic classifier, use [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). It is one of the simplest methods, but often it performs good enough in text classification tasks. It might take some time, because a number of classifiers to train is large.\n",
        "\n",
        "**OneVsRest multi-label strategy**\n",
        "\n",
        "The Multi-label algorithm accepts a binary mask over multiple labels. The result for each prediction will be an array of 0s and 1s marking which class labels apply to each row input sample.\n",
        "\n",
        "**Logistic Regression & SVM**\n",
        "\n",
        "OneVsRest strategy can be used for multi-label learning, where a classifier is used to predict multiple labels for instance. LR & SVM supports multi-class, but we are in a multi-label scenario, therefore, we wrap classifiers in the OneVsRestClassifier.\n",
        "\n",
        "*If you want to learn more about OneVsRest, check out these links:*\n",
        "- *https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5*\n",
        "- *https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff*\n",
        "- *https://medium.com/coinmonks/multi-label-classification-blog-tags-prediction-using-nlp-b0b5ee6686fc*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pj6MDkbTGAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUHZR2TWTGAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_classifier(x_train, y_train):\n",
        "    clf=OneVsRestClassifier(LogisticRegression()).fit(x_train,y_train)\n",
        "    return clf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k660NfRFTGAL",
        "colab_type": "text"
      },
      "source": [
        "Train the classifiers for different data transformations: *bag-of-words* and *tf-idf*.\n",
        "classifier_mybag = model for "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXyhN-yDTGAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ec19c3f1-8555-46b5-ca2a-945a1faa20f7"
      },
      "source": [
        "classifier_mybag = train_classifier(X_train_mybag, y_train)\n",
        "classifier_tfidf = train_classifier(x_train_tfidf, y_train)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijQZCd9cTGAU",
        "colab_type": "text"
      },
      "source": [
        "Now you can create predictions for the data. You will need two types of predictions: labels and scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QT7uWddTGAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
        "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
        "\n",
        "y_val_predicted_labels_tfidf = classifier_tfidf.predict(x_val_tfidf)\n",
        "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(x_val_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9n0TEtHTGAj",
        "colab_type": "text"
      },
      "source": [
        "Now, we would need to compare the results of different predictions, e.g. to see whether TF-IDF transformation helps or to try different regularization techniques in logistic regression. For all these experiments, we need to setup evaluation procedure. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVqAxDxqTGAk",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation (10 points)\n",
        "\n",
        "To evaluate the results we will use several classification metrics:\n",
        " - [Accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
        " - [F1-score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
        " - [Area under ROC-curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
        " - [Area under precision-recall curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) \n",
        " \n",
        "Make sure you are familiar with all of them. If you want a refresher, you can click the link to their documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YmNhVsU9K9-",
        "colab_type": "text"
      },
      "source": [
        "## Import the necessary libraries for the above metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBvrkOUYTGAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score \n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNkYBl_wTGAp",
        "colab_type": "text"
      },
      "source": [
        "Define the function *print_evaluation_scores* which takes y_val and predicted as input calculates and prints the following output:\n",
        " - *accuracy*\n",
        " - *F1-score - Average = 'weighted'* \n",
        " - *Precision - Average = 'macro'*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPCH5dqLp66L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3a9433a-c84f-40d2-c6d6-d4707aac79b3"
      },
      "source": [
        "print('y_val', y_val.shape) \n",
        "#print('X_val_tfidf ',X_val_tfidf.shape)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_val (30000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4nevWnhTGAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_evaluation_scores(y_val, predicted):\n",
        "    acc = accuracy_score(y_val, predicted, normalize=True, sample_weight=None)\n",
        "    precision_macro = average_precision_score(y_val, predicted, average='macro', sample_weight=None)\n",
        "    precision_micro = average_precision_score(y_val, predicted, average='micro', sample_weight=None)\n",
        "    precision_weight = average_precision_score(y_val, predicted, average='weighted', sample_weight=None)\n",
        "    f1_macro = average_precision_score(y_val, predicted, average='macro', sample_weight=None)\n",
        "    f1_micro = average_precision_score(y_val, predicted, average='micro', sample_weight=None)\n",
        "    f1_weight = average_precision_score(y_val, predicted, average='weighted', sample_weight=None)\n",
        "    return acc, precision_macro, precision_micro, precision_weight, f1_macro, f1_micro,f1_weight\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G92GIO4dTGAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "048b4d74-2279-45ad-bf94-175d6bf054f6"
      },
      "source": [
        "print('Bag-of-words')\n",
        "print_evaluation_scores(y_val, y_val_predicted_labels_mybag)\n",
        "print('Tfidf')\n",
        "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag-of-words\n",
            "Tfidf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.33366666666666667,\n",
              " 0.30075521722803006,\n",
              " 0.4552773512290578,\n",
              " 0.483600447051642,\n",
              " 0.30075521722803006,\n",
              " 0.4552773512290578,\n",
              " 0.483600447051642)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT7oso8ZTGAv",
        "colab_type": "text"
      },
      "source": [
        "You might also want to plot some form of the [ROC curve](http://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc) for the case of multi-label classification. The input parameters for the roc curve are:\n",
        " - true labels\n",
        " - decision functions scores\n",
        " - number of classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4hbW3SeBVxz",
        "colab_type": "text"
      },
      "source": [
        "Import the roc_auc function from the metrics.py file provided"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xaSXRj6tLmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_9M0AI4TGAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "9060caa5-d55f-491f-b93e-00236583496d"
      },
      "source": [
        "n_classes = len(tags_counts)\n",
        "roc_curve(y_val, y_val_predicted_scores_mybag, n_classes)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-234-c1e4a103b15e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_predicted_scores_mybag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \"\"\"\n\u001b[1;32m    621\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 622\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    394\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    395\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multilabel-indicator format is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZaymN4uTGA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roc_auc(y_val, y_val_predicted_scores_tfidf, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwNpUEVLTGA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S3Ddz7LTGA3",
        "colab_type": "text"
      },
      "source": [
        "## Task 4 (MultilabelClassification) - Optional \n",
        "** Once we have the evaluation set up, we suggest that you experiment a bit with training your classifiers. We will use *F1-score weighted* as an evaluation metric. Our recommendation:\n",
        "- compare the quality of the bag-of-words and TF-IDF approaches and chose one of them.\n",
        "- for the chosen one, try *L1* and *L2*-regularization techniques in Logistic Regression with different coefficients (e.g. C equal to 0.1, 1, 10, 100).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ers40KuOTGA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################\n",
        "######### YOUR CODE HERE #############\n",
        "######################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdqTO269TGA8",
        "colab_type": "text"
      },
      "source": [
        "When you are happy with the quality, create predictions for *test* set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M51F10f9TGBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}